<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Scrapeando las Sesiones Parlamentarias de Uruguay"/>
  <meta name="twitter:description" content="En Uruguay venimos avanzando con las iniciativas de datos abiertos, pero a√∫n queda mucho camino por recorrer. Uno de los impedimentos para analizar datos es que no siempre son f√°cilmente consumibles, sea porque no hay una forma sistem√°tica de descargarlos o porque est√°n en formato pdf, que no es muy amigable para ser interpretado por m√°quinas. En este art√≠culo muestro c√≥mo se pueden sortear ambas dificultades usando los paquetes rvest y pdftools respectivamente, y tener los Diarios de Sesiones descargados en el mejor formato posible para analizarlos."/>
  
    <meta name="twitter:site" content="@your_twitter_id"/>
  
  
  
  
    <meta name="twitter:creator" content="@site_author"/>
  



		
		<meta name="author" content="site_author">
		<meta name="description" content="Site Description">
		<meta name="generator" content="Hugo 0.59.1" />
		<title>Scrapeando las Sesiones Parlamentarias de Uruguay &middot; d4tagirl</title>
		<link rel="shortcut icon" href="/images/favicon.ico">
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/highlight.css">

		
		<link rel="stylesheet" href="/css/font-awesome.min.css">
		

		
		<link href="/index.xml" rel="alternate" type="application/rss+xml" title="d4tagirl" />
		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='/'> <span class="arrow">‚Üê</span>Home</a>
	
	<a href='/posts'>Archive</a>
	<a href='/tags'>Tags</a>
	<a href='/about'>About</a>

	

	
	<a class="cta" href="/index.xml">Subscribe</a>
	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Scrapeando las Sesiones Parlamentarias de Uruguay
                    </h1>
                    <h2 class="headline">
                    Jan 1, 0001 00:00
                    ¬∑ 2798 words
                    ¬∑ 14 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="/tags/rstats">rstats</a>
                          
                              <a href="/tags/open-data">open data</a>
                          
                              <a href="/tags/scraping">scraping</a>
                          
                              <a href="/tags/rvest">rvest</a>
                          
                              <a href="/tags/pdftools">pdftools</a>
                          
                              <a href="/tags/parlamento">parlamento</a>
                          
                              <a href="/tags/uruguay">uruguay</a>
                          
                              <a href="/tags/senadores">senadores</a>
                          
                              <a href="/tags/diputados">diputados</a>
                          
                              <a href="/tags/es">es</a>
                          
                              <a href="/tags/r">r</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                    <div id="toc">
                      <nav id="TableOfContents">
<ul>
<li><a href="#est√°-permitido-que-un-robot-se-comunique-con-estas-p√°ginas">Est√° permitido que un robot se comunique con estas p√°ginas?</a></li>
<li><a href="#url-de-las-p√°ginas-que-quiero-scrapear">Url de las p√°ginas que quiero <em>scrapear</em></a></li>
<li><a href="#y-ahora-c√≥mo-selecciono-el-contenido-de-la-p√°gina">Y ahora? C√≥mo selecciono el contenido de la p√°gina?</a></li>
<li><a href="#web-scraping">Web scraping!</a>
<ul>
<li><a href="#extraigo-los-pdfs">Extraigo los pdfs</a>
<ul>
<li><a href="#advertencia">‚ö†Ô∏è Advertencia ‚ö†Ô∏è</a></li>
</ul></li>
<li><a href="#extraigo-fecha-y-n√∫mero-de-sesi√≥n">Extraigo fecha y n√∫mero de sesi√≥n</a></li>
</ul></li>
<li><a href="#tad√°">Tad√° üéâ</a></li>
</ul>
</nav>
                    </div>
                  
                
                <section id="post-body">
                    <p>En Uruguay venimos avanzando con las iniciativas de datos abiertos, pero a√∫n queda mucho camino por recorrer. Uno de los impedimentos para analizar datos es que no siempre son f√°cilmente consumibles, sea porque no hay una forma sistem√°tica de descargarlos o porque est√°n en formato pdf, que no es muy amigable para ser interpretado por m√°quinas. En este art√≠culo muestro c√≥mo se pueden sortear ambas dificultades usando los paquetes <a href="https://github.com/tidyverse/rvest">rvest</a> y <a href="https://github.com/ropensci/pdftools">pdftools</a> respectivamente, y tener los Diarios de Sesiones descargados en el mejor formato posible para analizarlos.</p>

<p>En Uruguay venimos avanzando con las iniciativas de datos abiertos, pero a√∫n queda mucho camino por recorrer. Algunas de las dificultades para analizar datos abiertos son:</p>

<ul>
<li><p>Que no siempre no es f√°cil acceder a ellos de forma sistem√°tica:
por ejemplo porque no est√°n todos juntos en un archivo comprimido para descargarlos, o no existe una API para acceder a la informaci√≥n,</p></li>

<li><p>Que est√°n en formato pdf del que no es tan f√°cil extraer informaci√≥n como de un archivo txt o csv, por nombrar algunos formatos.</p></li>
</ul>

<p>En particular hay dos problemas que quiero resolver:</p>

<ul>
<li><p>Descargar los archivos en formato pdf de las Sesiones Parlamentarias de Diputados y Senadores de forma sistem√°tica, haciendo <a href="https://es.wikipedia.org/wiki/Web_scraping">lo que se conoce como <em>web scraping</em></a>.</p></li>

<li><p>Extraer el texto contenido en los archivos en formato pdf.</p></li>
</ul>

<p>En este art√≠culo muestro c√≥mo se pueden sortear ambas dificultades, usando los paquetes <a href="https://github.com/tidyverse/rvest">rvest</a> para explorar la web y descargar los Diarios de Sesiones, y <a href="https://github.com/ropensci/pdftools">pdftools</a> para extraer el contenido de los archivos en formato pdf.</p>

<h1 id="est√°-permitido-que-un-robot-se-comunique-con-estas-p√°ginas">Est√° permitido que un robot se comunique con estas p√°ginas?</h1>

<p>Si bien se trata de datos abiertos, hay ciertas normas <em>de etiqueta</em> que es recomendable seguir. Respetar las reglas que establecieron los que administran el sitio acerca de c√≥mo quieren que la gente lo use es una de ellas. Puede ser que s√≥lo quieran que se navegue <em>a mano</em>, entonces no deber√≠a intentar acceder de la forma en que estoy planeando.</p>

<p>Para ver si la secci√≥n del sitio web que quiero navegar permite ser accedida por un <em>robot</em> (que es lo que pretendo construir! ü§ñ), examino <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">el archivo <em>robots.txt</em></a>, donde se establece para cada secci√≥n del sitio si este uso es adecuado. Desde R se puede hacer f√°cilmente usando <a href="https://github.com/ropensci/robotstxt">el parquete robotstxt</a> de <a href="https://ropensci.org/">rOpenSci</a>, que <a href="https://masalmon.eu/2017/10/02/guardian-experience/">Ma√´lle mencion√≥ en su post donde scrapea datos de <em>The Guardian</em></a>.</p>

<p>Este es todo el archivo <em>robots.txt</em> del <a href="https://parlamento.gub.uy">sitio web del Parlamento</a>:</p>

<pre><code class="language-r">robotstxt::get_robotstxt(&quot;https://parlamento.gub.uy&quot;)
</code></pre>

<pre><code>## #
## # robots.txt
## #
## # This file is to prevent the crawling and indexing of certain parts
## # of your site by web crawlers and spiders run by sites like Yahoo!
## # and Google. By telling these &quot;robots&quot; where not to go on your site,
## # you save bandwidth and server resources.
## #
## # This file will be ignored unless it is at the root of your host:
## # Used:    http://example.com/robots.txt
## # Ignored: http://example.com/site/robots.txt
## #
## # For more information about the robots.txt standard, see:
## # http://www.robotstxt.org/robotstxt.html
## 
## User-agent: *
## Crawl-delay: 10
## # CSS, JS, Images
## Allow: /misc/*.css$
## Allow: /misc/*.css?
## Allow: /misc/*.js$
## Allow: /misc/*.js?
## Allow: /misc/*.gif
## Allow: /misc/*.jpg
## Allow: /misc/*.jpeg
## Allow: /misc/*.png
## Allow: /modules/*.css$
## Allow: /modules/*.css?
## Allow: /modules/*.js$
## Allow: /modules/*.js?
## Allow: /modules/*.gif
## Allow: /modules/*.jpg
## Allow: /modules/*.jpeg
## Allow: /modules/*.png
## Allow: /profiles/*.css$
## Allow: /profiles/*.css?
## Allow: /profiles/*.js$
## Allow: /profiles/*.js?
## Allow: /profiles/*.gif
## Allow: /profiles/*.jpg
## Allow: /profiles/*.jpeg
## Allow: /profiles/*.png
## Allow: /themes/*.css$
## Allow: /themes/*.css?
## Allow: /themes/*.js$
## Allow: /themes/*.js?
## Allow: /themes/*.gif
## Allow: /themes/*.jpg
## Allow: /themes/*.jpeg
## Allow: /themes/*.png
## # Directories
## Disallow: /includes/
## Disallow: /misc/
## Disallow: /modules/
## Disallow: /profiles/
## Disallow: /scripts/
## Disallow: /themes/
## # Files
## Disallow: /CHANGELOG.txt
## Disallow: /cron.php
## Disallow: /INSTALL.mysql.txt
## Disallow: /INSTALL.pgsql.txt
## Disallow: /INSTALL.sqlite.txt
## Disallow: /install.php
## Disallow: /INSTALL.txt
## Disallow: /LICENSE.txt
## Disallow: /MAINTAINERS.txt
## Disallow: /update.php
## Disallow: /UPGRADE.txt
## Disallow: /xmlrpc.php
## # Paths (clean URLs)
## Disallow: /admin/
## Disallow: /comment/reply/
## Disallow: /filter/tips/
## Disallow: /node/add/
## Disallow: /search/
## Disallow: /user/register/
## Disallow: /user/password/
## Disallow: /user/login/
## Disallow: /user/logout/
## # Paths (no clean URLs)
## Disallow: /?q=admin/
## Disallow: /?q=comment/reply/
## Disallow: /?q=filter/tips/
## Disallow: /?q=node/add/
## Disallow: /?q=search/
## Disallow: /?q=user/password/
## Disallow: /?q=user/register/
## Disallow: /?q=user/login/
## Disallow: /?q=user/logout/
</code></pre>

<p><a href="https://stackoverflow.com/a/40186203/7248543">Lo que no aparece como <em>&ldquo;Disallow&rdquo;</em> es permitido por defecto</a>, y la url a la que quiero acceder usando un robot es <a href="https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion">https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion</a>. No dice en ning√∫n lugar del documento <code>Disallow: /documentosyleyes/</code>, entonces est√° permitido!</p>

<p>Pero por las dudas, chequeo esa url en particular:</p>

<pre><code class="language-r">robotstxt::paths_allowed(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion&quot;)
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

<p>Tengo luz verde para scrapear la web üôå.</p>

<h1 id="url-de-las-p√°ginas-que-quiero-scrapear">Url de las p√°ginas que quiero <em>scrapear</em></h1>

<p>Mi intenci√≥n es descargar las sesiones de Diputados y Senadores desde el 1¬∫/1/2017 hasta el 31/3/2018. Al incorporar estos filtros manualmente en la p√°gina <a href="https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion">https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion</a>, la url se va modificando para incorporar esta informaci√≥n. Eso hace las cosas algo menos complicadas para mi, porque una vez que me doy cuenta c√≥mo se comporta la url con esos filtros, puedo generar la url nueva y directamente acceder a ella. As√≠ construyo la nueva url que se compone de la url original, algo de texto adicional y los filtros de fechas, de la siguiente forma:</p>

<pre><code class="language-r">date_init &lt;- &quot;01-01-2017&quot;
date_end  &lt;- &quot;31-03-2018&quot;

url_diputados &lt;- paste0(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=D&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=&quot;,
                        date_init,
                        &quot;&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=&quot;,
                        date_end,
                        &quot;&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;)
url_diputados
</code></pre>

<pre><code>## [1] &quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=D&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=01-01-2017&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=31-03-2018&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;
</code></pre>

<pre><code class="language-r">url_senadores &lt;- paste0(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=S&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=&quot;,
                        date_init,
                        &quot;&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=&quot;,
                        date_end,
                        &quot;&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;)

url_senadores
</code></pre>

<pre><code>## [1] &quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=S&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=01-01-2017&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=31-03-2018&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;
</code></pre>

<h1 id="y-ahora-c√≥mo-selecciono-el-contenido-de-la-p√°gina">Y ahora? C√≥mo selecciono el contenido de la p√°gina?</h1>

<p>Las p√°ginas web son archivos html que el navegador interpreta y los transforma en lo que nosotros vemos. No voy a entrar en muchos detalles de c√≥mo interpretar un archivo html (porque reci√©n estoy aprendiendo!), pero ac√° describo la  forma m√°s intuitiva que encontr√© para seleccionar el contenido del html al que quiero acceder.</p>

<p>Como se muestra en la animaci√≥n a continuaci√≥n, usando el <a href="https://selectorgadget.com/">Selector Gadget</a> (que tiene una extensi√≥n para Google Chrome muy conveniente) me paro con el mouse sobre uno de los links a los pdfs y hago click. Ah√≠ queda pintada toda la columna, porque pinta todos los elementos que son de la misma <em>clase</em> (no nos preocupemos de qu√© es una <em>clase</em> ahora). Lo importante es que necesito <em>el nombre de la clase</em> para lo que viene a continuaci√≥n, entonces copio el texto que aparece en el recuadro (en este caso es <code>.views-field-DS-File-IMG</code>).</p>

<p><img src="/figure/source/scrapeando-las-sesiones-parlamentarias-de-uruguay/2018-04-03-scrapeando-las-sesiones-parlamentarias-de-uruguay/selector_gadget.gif" alt="" /></p>

<h1 id="web-scraping">Web scraping!</h1>

<h2 id="extraigo-los-pdfs">Extraigo los pdfs</h2>

<p>Ahora es que empiezo a usar el paquete <a href="https://github.com/tidyverse/rvest">rvest</a>. Defino una funci√≥n que descarga los pdfs y los guarda en un dataframe, haciendo algunas transformaciones. Para explicar lo que hace la funci√≥n voy a ignorar que como las sesiones son muchas, las muestra en dos p√°ginas separadas. Es verdad que podr√≠a haber puesto un poco m√°s de esfuerzo en hacer esta funci√≥n generalizable a <em>n</em> p√°ginas, pero como sab√≠a que ten√≠a s√≥lo 2, lo dej√© as√≠ üòá</p>

<pre><code class="language-r">library(dplyr)
library(rvest)
library(purrr)
library(tibble)
library(pdftools)

extract_pdf &lt;- function(url, pag = 1) {
  
  if (pag == 2) {
    url &lt;- url %&gt;%
      read_html() %&gt;%
      html_nodes(&quot;.pager-item a&quot;) %&gt;%
      html_attr(&quot;href&quot;) %&gt;%
      map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
      unlist()
    }
  
  pdfs &lt;- url %&gt;%
    read_html() %&gt;%
    html_nodes(&quot;.views-field-DS-File-IMG a&quot;) %&gt;%   # seleccionar clase
    html_attr(&quot;href&quot;) %&gt;%
    map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
    map(~ paste0(pdf_text(.), collapse = ' ')) %&gt;%
    map(~ stri_trans_general(tolower(.), id = &quot;latin-ascii&quot;)) %&gt;%
    map(~ stri_replace_all(., replacement = &quot;&quot;, regex = &quot;\\\n&quot;)) %&gt;% 
    map_df(function(pdf) {tibble(pdf)})
  
  return(pdfs)
}
</code></pre>

<p>La primera parte de la funci√≥n es la que voy a ignorar, donde lo que hago es modificar la url para indicar que quiero ir a la segunda p√°gina (se puede aplicar la misma l√≥gica que la que voy a usar a continuaci√≥n para interpretar esta parte del c√≥digo).</p>

<p>Lo interesante pasa cuando empiezo a procesar la url: <code>read_html()</code> &ldquo;lee&rdquo; el contenido de la p√°gina, para que pueda buscar lo que me interesa. Mi objetivo es encontrar todos los archivos pdf (por eso me interesaba conocer <em>el nombre de la clase</em> de esos elementos, que descubr√≠ antes). Con <code>html_nodes()</code> voy extrayendo los <em>nodos</em> (tampoco nos preocupemos ahora por saber qu√© son exactamente), y en este caso el <em>nodo</em> que me interesa es <code>.views-field-DS-File-IMG a</code>:</p>

<ul>
<li><p>tiene un punto adelante para indicar que se trata de elementos de una clase, seguido del nombre de la clase <code>views-field-DS-File-IMG</code> (lo que copiamos con el <em>Selector Gadget</em>),</p></li>

<li><p><code>a</code> es la etiqueta que html usa para definir elementos que son un hiperv√≠nculo.</p></li>
</ul>

<p>Ahora puedo seleccionar el atributo <code>href</code>, que es el link al pdf, con la funci√≥n <code>html_attr()</code>. Ac√° hay que tener cuidado porque la ruta es relativa (es decir que falta poner &ldquo;<a href="https://parlamento.gub.uy&quot;">https://parlamento.gub.uy&quot;</a> antes para tener la ruta completa).</p>

<p>Al aplicar la funci√≥n hasta ac√°, lo que tengo es una lista con una url por cada pdf que aparece en la p√°gina. Por eso luego uso la funci√≥n <code>purrr::map()</code> para aplicar a cada elemento de la lista (cada link a los pdfs), una funci√≥n. Las transformaciones que aplico a cada elemento de la lista son, en forma sucesiva, las siguientes:</p>

<ul>
<li><p><code>paste0(&quot;https://parlamento.gub.uy&quot;, .)</code> completo la ruta absoluta, pegando &ldquo;<a href="https://parlamento.gub.uy&quot;">https://parlamento.gub.uy&quot;</a> adelante del link relativo,</p></li>

<li><p><code>paste0(pdf_text(.), collapse = ' ')</code> usando el paquete <code>pdftools</code> extraigo la informaci√≥n del pdf con la funci√≥n <code>pdf_text()</code> y colapso todas las p√°ginas en un mismo string,</p></li>

<li><p><code>stri_trans_general(tolower(.), id = &quot;latin-ascii&quot;)</code> saco los caracteres especiales y dejo todo en min√∫scula,</p></li>

<li><p><code>stri_replace_all(., replacement = &quot;&quot;, regex = &quot;\\\n&quot;)</code> elimino los saltos de l√≠nea,</p></li>

<li><p><code>tibble(pdf)</code> transformo la lista en un dataframe.</p></li>
</ul>

<p>Entonces ahora extraigo los pdfs de las dos p√°ginas y los junto en un √∫nico dataframe (voy a mostrar el proceso para Diputados, pero es an√°logo para Senadores).</p>

<pre><code class="language-r">pdf_diputados_pag1 &lt;- extract_pdf(url_diputados, pag = 1)
pdf_diputados_pag2 &lt;- extract_pdf(url_diputados, pag = 2)

pdf_diputados &lt;- bind_rows(pdf_diputados_pag1, pdf_diputados_pag2)

library(knitr)
library(kableExtra)

knitr::kable(head(pdf_diputados) %&gt;%
               select(pdf) %&gt;% 
               mutate(pdf = substr(pdf, start=1, stop=500)),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> numero 4151                                                          montevideo, miercoles 14 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                               5¬™ sesion (extraordinaria)
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4148                                                              montevideo, martes 6 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                                2¬™ sesion
                                  presiden los senores representantes
                                                jorge gandini
                                                  (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4147                                                              montevideo, jueves 1¬∞ de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                               1¬™ sesion
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4146                                                             montevideo, jueves 8 de febrero de 2018
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               3¬™ sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (preside </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4145                                                  montevideo, miercoles 7 de febrero de 2018
                 republica oriental del uruguay
                    diario de sesiones
                camara de representantes
                       2¬™ sesion (extraordinaria)
                             preside el senor representante
                                  prof. jose carlos mahia
                                          (presidente)
                             actuan en secret </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4144                                                         montevideo, miercoles 20 de diciembre de 2017
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               1¬™ sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (presi </td>
  </tr>
</tbody>
</table>

<h3 id="advertencia">‚ö†Ô∏è Advertencia ‚ö†Ô∏è</h3>

<p>La funci√≥n <code>pdftools::read_pdf()</code> lee los renglones de izquierda a derecha. En los Diarios de Sesiones hay algunas p√°ginas que se organizan con texto en dos columnas, entonces hay renglones que, le√≠dos de esa forma, quedan incoherentes. Esto hay que tenerlo en cuenta para ver si el tipo de an√°lisis que quiero hacer tiene sentido o no. Por ejemplo, si lo que quiero es analizar <a href="https://es.wikipedia.org/wiki/N-grama"><em>n-gramas</em></a> donde el orden de las palabras es importante, voy a tener problemas porque estar√≠a considerando palabras de distintas columnas de texto, como si vinieran una a continuaci√≥n de la otra. Para analizar sentimiento con <a href="https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras"><em>bolsa de palabras (bag of words)</em></a> no hay problema, porque el orden de las palabras no es relevante.</p>

<h2 id="extraigo-fecha-y-n√∫mero-de-sesi√≥n">Extraigo fecha y n√∫mero de sesi√≥n</h2>

<p>Hago una segunda funci√≥n para extraer otros la fecha y el n√∫mero de la sesi√≥n, porque se puede dar el caso de tener m√°s de una sesi√≥n en la misma fecha.</p>

<pre><code class="language-r">extract_metadata &lt;- function(url, info, pag = 1){
  if (info == &quot;fecha&quot;) nodes = &quot;td.views-field-DS-Fecha&quot;
  if (info == &quot;sesion&quot;) nodes = &quot;td.views-field-Ssn-Nro&quot;
  if (pag == 2){
    url &lt;- url %&gt;%
      read_html() %&gt;%
      html_nodes(&quot;.pager-item a&quot;) %&gt;%
      html_attr(&quot;href&quot;) %&gt;%
      map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
      unlist() 
    }
  
  url %&gt;% 
    read_html() %&gt;% 
    html_nodes(nodes) %&gt;% 
    html_text() %&gt;% 
    map(~str_extract(., &quot;[0-9\\-]+&quot;)) %&gt;%  # esta expresi√≥n regular matchea tanto la fecha como el n√∫mero de sesi√≥n
    unlist()
}
</code></pre>

<p>Extraigo la fecha y la sesi√≥n.</p>

<pre><code class="language-r"># extraigo fechas
pdf_fechas_diputados_pag1 &lt;- extract_metadata(url_diputados, info = &quot;fecha&quot;, pag = 1)
pdf_fechas_diputados_pag2 &lt;- extract_metadata(url_diputados, info = &quot;fecha&quot;, pag = 2)

# junto todos las fechas y las convierto en un df
pdf_fechas_diputados &lt;- c(pdf_fechas_diputados_pag1, pdf_fechas_diputados_pag2) %&gt;% 
  tbl_df() %&gt;% 
  transmute(fecha = as.Date(value, &quot;%d-%m-%Y&quot;))

# extraigo sesiones
pdf_sesion_diputados_pag1 &lt;- extract_metadata(url_diputados, info = &quot;sesion&quot;, pag = 1)
pdf_sesion_diputados_pag2 &lt;- extract_metadata(url_diputados, info = &quot;sesion&quot;, pag = 2)

# junto todos las sesiones y las convierto en un df
pdf_sesion_diputados &lt;- c(pdf_sesion_diputados_pag1, pdf_sesion_diputados_pag2) %&gt;% 
  tbl_df() %&gt;% 
  rename(sesion = value)

knitr::kable(head(pdf_sesion_diputados) %&gt;% select(fecha),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-14 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-06 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-01 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-08 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-20 </td>
  </tr>
</tbody>
</table>

<pre><code class="language-r">knitr::kable(head(pdf_sesion_diputados) %&gt;% select(sesion),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> sesion </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 5 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 3 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
  </tr>
</tbody>
</table>
Juntando todo, armo el dataframe de Diputados con la fecha, la sesi√≥n y el texto del pdf.


```r
diputados <- bind_cols(pdf_fechas_diputados, pdf_sesion_diputados, pdf_diputados) %>% 
  unite("fecha_sesion", c(fecha, sesion), remove = FALSE) %>%
  distinct() # la primer sesi√≥n de la segunda p√°gina es igual a la √∫ltima sesi√≥n de la primera p√°gina
```

Con este dataframe es con el que voy a trabajar para los Diputados, que tiene 66 sesiones.


```r
knitr::kable(head(diputados) %>% 
               mutate(pdf = substr(pdf, start=1, stop=500)), 
             format = "html") 
```

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha_sesion </th>
   <th style="text-align:left;"> fecha </th>
   <th style="text-align:left;"> sesion </th>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-14_5 </td>
   <td style="text-align:left;"> 2018-03-14 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> numero 4151                                                          montevideo, miercoles 14 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                               5¬™ sesion (extraordinaria)
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-06_2 </td>
   <td style="text-align:left;"> 2018-03-06 </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> numero 4148                                                              montevideo, martes 6 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                                2¬™ sesion
                                  presiden los senores representantes
                                                jorge gandini
                                                  (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-01_1 </td>
   <td style="text-align:left;"> 2018-03-01 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> numero 4147                                                              montevideo, jueves 1¬∞ de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                               1¬™ sesion
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-08_3 </td>
   <td style="text-align:left;"> 2018-02-08 </td>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> numero 4146                                                             montevideo, jueves 8 de febrero de 2018
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               3¬™ sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (preside </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07_2 </td>
   <td style="text-align:left;"> 2018-02-07 </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> numero 4145                                                  montevideo, miercoles 7 de febrero de 2018
                 republica oriental del uruguay
                    diario de sesiones
                camara de representantes
                       2¬™ sesion (extraordinaria)
                             preside el senor representante
                                  prof. jose carlos mahia
                                          (presidente)
                             actuan en secret </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-20_1 </td>
   <td style="text-align:left;"> 2017-12-20 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> numero 4144                                                         montevideo, miercoles 20 de diciembre de 2017
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               1¬™ sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (presi </td>
  </tr>
</tbody>
</table>

<p>Y con este dataframe es con el que voy a trabajar para los Senadores, que tiene 59 sesiones.</p>

<pre><code class="language-r">knitr::kable(head(senadores) %&gt;% 
               mutate(pdf = substr(pdf, start=1, stop=500)), 
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha_sesion </th>
   <th style="text-align:left;"> fecha </th>
   <th style="text-align:left;"> sesion </th>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-06_1 </td>
   <td style="text-align:left;"> 2018-03-06 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> n.¬∫ 1 - tomo 578                                                                                                      6 de marzo de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                  camara de senadores                                      cuarto periodo de la xlviii legislatura </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-27_57 </td>
   <td style="text-align:left;"> 2018-02-27 </td>
   <td style="text-align:left;"> 57 </td>
   <td style="text-align:left;"> n.¬∫ 57 - tomo 577                                                                                                    27 de febrero de 2018                                            republica oriental del uruguay                            diario de sesiones                                                                       de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                   57 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-21_56 </td>
   <td style="text-align:left;"> 2018-02-21 </td>
   <td style="text-align:left;"> 56 </td>
   <td style="text-align:left;"> n.¬∫ 56 - tomo 577                                                                                                   21 de febrero de 2018                                            republica oriental del uruguay                            diario de sesiones                                                                       de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  56.¬™ </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07_55 </td>
   <td style="text-align:left;"> 2018-02-07 </td>
   <td style="text-align:left;"> 55 </td>
   <td style="text-align:left;"> n.¬∫ 55 - tomo 577                                                                                                       7 de febrero de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  55. </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-06_54 </td>
   <td style="text-align:left;"> 2018-02-06 </td>
   <td style="text-align:left;"> 54 </td>
   <td style="text-align:left;"> n.¬∫ 54 - tomo 577                                                                                                    6 de febrero de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  54.¬™ s </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-27_53 </td>
   <td style="text-align:left;"> 2017-12-27 </td>
   <td style="text-align:left;"> 53 </td>
   <td style="text-align:left;"> n.¬∫ 53 - tomo 577                                                                                                27 de diciembre de 2017                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  53.¬™ se </td>
  </tr>
</tbody>
</table>

<h1 id="tad√°">Tad√° üéâ</h1>

<p>Ahora con los datos en este formato, estoy en condiciones de analizar las sesiones!</p>

<p>Para m√°s informaci√≥n acerca de c√≥mo trabajar con datos de la web, hay un <a href="https://www.datacamp.com/community/tutorials/r-web-scraping-rvest">tutorial de Arvid Kingl en Datacamp en ingl√©s para usar <code>rvest</code></a> y hay un <a href="https://www.datacamp.com/courses/working-with-web-data-in-r">curso de Charlotte Wickham y Oliver Keyes, tambi√©n en ingl√©s y en Datacamp,</a> que habla adem√°s de otras formas de consumir datos de la web, como a trav√©s de APIs.</p>

<p>Si quer√©s analizar las sesiones fuera de R, o prefer√≠s ahorrarte el paso de hacer scraping, <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary/blob/master/data/diputados.csv">ac√° ten√©s las sesiones de Diputados en formato csv</a>, y <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary/blob/master/data/senadores.csv">ac√° las sesiones de Senadores en formato csv</a> para hacer tus an√°lisis! (Gracias <a href="https://twitter.com/rolaguna">Rodrigo</a> por la sugerencia!)</p>

<p>Todo lo que us√© en este art√≠culo (y m√°s!) est√° <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary">disponible en GitHub</a>. Espero que haya resultado √∫til! Dejame tus comentarios abajo o <a href="https://twitter.com/intent/tweet?user_id=114258616">mencioname en Twitter</a> üòÉ</p>
                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=%2f1%2f01%2fscrapeando-las-sesiones-parlamentarias-de-uruguay%2f - Scrapeando%20las%20Sesiones%20Parlamentarias%20de%20Uruguay by @your_twitter_id"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'your_disqus_short_name'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/nodejh">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.twitter.com/nodejh">
        <i class="fa fa-twitter-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       ¬© Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> site_author
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'your_google_analytics_id', 'auto');
	
	ga('send', 'pageview');
}
</script>





    </body>
</html>
