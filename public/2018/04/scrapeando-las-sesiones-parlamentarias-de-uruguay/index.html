<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		 
			
  
    <meta name="twitter:card" content="summary"/>
    
      <meta name="twitter:image" content="/images/avatar.png" />
    
  
  
  <meta name="twitter:title" content="Scrapeando las Sesiones Parlamentarias de Uruguay"/>
  <meta name="twitter:description" content="En Uruguay venimos avanzando con las iniciativas de datos abiertos, pero a칰n queda mucho camino por recorrer. Uno de los impedimentos para analizar datos es que no siempre son f치cilmente consumibles, sea porque no hay una forma sistem치tica de descargarlos o porque est치n en formato pdf, que no es muy amigable para ser interpretado por m치quinas. En este art칤culo muestro c칩mo se pueden sortear ambas dificultades usando los paquetes rvest y pdftools respectivamente, y tener los Diarios de Sesiones descargados en el mejor formato posible para analizarlos."/>
  
    <meta name="twitter:site" content="@114258616"/>
  
  
  
  
    <meta name="twitter:creator" content="@Daniela V치zquez"/>
  



		
		<meta name="author" content="Daniela V치zquez">
		<meta name="description" content="A blog about a girl who found her way into data science :)">
		<meta name="generator" content="Hugo 0.59.1" />
		<title>Scrapeando las Sesiones Parlamentarias de Uruguay &middot; d4tagirl</title>
		<link rel="shortcut icon" href="/images/favicon.ico">
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/highlight.css">

		
		<link rel="stylesheet" href="/css/font-awesome.min.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='/'> Home</a>
	
	<a href='/about'>About</a>
	<a href='/talks'>Talks</a>
	<a href='/community'>Community</a>

	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Scrapeando las Sesiones Parlamentarias de Uruguay
                    </h1>
                    <h2 class="headline">
                        Apr 3, 2018  
                    췅 2711 words
                    췅 13 minute read 
                    </h2>
                </header>
                
                <br>
                <br>
                <section id="post-body">
                    

<p>En Uruguay venimos avanzando con las iniciativas de datos abiertos, pero a칰n queda mucho camino por recorrer. Algunas de las dificultades para analizar datos abiertos son:</p>

<ul>
<li><p>Que no siempre no es f치cil acceder a ellos de forma sistem치tica:
por ejemplo porque no est치n todos juntos en un archivo comprimido para descargarlos, o no existe una API para acceder a la informaci칩n,</p></li>

<li><p>Que est치n en formato pdf del que no es tan f치cil extraer informaci칩n como de un archivo txt o csv, por nombrar algunos formatos.</p></li>
</ul>

<p>En particular hay dos problemas que quiero resolver:</p>

<ul>
<li><p>Descargar los archivos en formato pdf de las Sesiones Parlamentarias de Diputados y Senadores de forma sistem치tica, haciendo <a href="https://es.wikipedia.org/wiki/Web_scraping">lo que se conoce como <em>web scraping</em></a>.</p></li>

<li><p>Extraer el texto contenido en los archivos en formato pdf.</p></li>
</ul>

<p>En este art칤culo muestro c칩mo se pueden sortear ambas dificultades, usando los paquetes <a href="https://github.com/tidyverse/rvest">rvest</a> para explorar la web y descargar los Diarios de Sesiones, y <a href="https://github.com/ropensci/pdftools">pdftools</a> para extraer el contenido de los archivos en formato pdf.</p>

<h1 id="est치-permitido-que-un-robot-se-comunique-con-estas-p치ginas">Est치 permitido que un robot se comunique con estas p치ginas?</h1>

<p>Si bien se trata de datos abiertos, hay ciertas normas <em>de etiqueta</em> que es recomendable seguir. Respetar las reglas que establecieron los que administran el sitio acerca de c칩mo quieren que la gente lo use es una de ellas. Puede ser que s칩lo quieran que se navegue <em>a mano</em>, entonces no deber칤a intentar acceder de la forma en que estoy planeando.</p>

<p>Para ver si la secci칩n del sitio web que quiero navegar permite ser accedida por un <em>robot</em> (que es lo que pretendo construir! 游뱄), examino <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">el archivo <em>robots.txt</em></a>, donde se establece para cada secci칩n del sitio si este uso es adecuado. Desde R se puede hacer f치cilmente usando <a href="https://github.com/ropensci/robotstxt">el parquete robotstxt</a> de <a href="https://ropensci.org/">rOpenSci</a>, que <a href="https://masalmon.eu/2017/10/02/guardian-experience/">Ma칢lle mencion칩 en su post donde scrapea datos de <em>The Guardian</em></a>.</p>

<p>Este es todo el archivo <em>robots.txt</em> del <a href="https://parlamento.gub.uy">sitio web del Parlamento</a>:</p>

<pre><code class="language-r">robotstxt::get_robotstxt(&quot;https://parlamento.gub.uy&quot;)
</code></pre>

<pre><code>## #
## # robots.txt
## #
## # This file is to prevent the crawling and indexing of certain parts
## # of your site by web crawlers and spiders run by sites like Yahoo!
## # and Google. By telling these &quot;robots&quot; where not to go on your site,
## # you save bandwidth and server resources.
## #
## # This file will be ignored unless it is at the root of your host:
## # Used:    http://example.com/robots.txt
## # Ignored: http://example.com/site/robots.txt
## #
## # For more information about the robots.txt standard, see:
## # http://www.robotstxt.org/robotstxt.html
## 
## User-agent: *
## Crawl-delay: 10
## # CSS, JS, Images
## Allow: /misc/*.css$
## Allow: /misc/*.css?
## Allow: /misc/*.js$
## Allow: /misc/*.js?
## Allow: /misc/*.gif
## Allow: /misc/*.jpg
## Allow: /misc/*.jpeg
## Allow: /misc/*.png
## Allow: /modules/*.css$
## Allow: /modules/*.css?
## Allow: /modules/*.js$
## Allow: /modules/*.js?
## Allow: /modules/*.gif
## Allow: /modules/*.jpg
## Allow: /modules/*.jpeg
## Allow: /modules/*.png
## Allow: /profiles/*.css$
## Allow: /profiles/*.css?
## Allow: /profiles/*.js$
## Allow: /profiles/*.js?
## Allow: /profiles/*.gif
## Allow: /profiles/*.jpg
## Allow: /profiles/*.jpeg
## Allow: /profiles/*.png
## Allow: /themes/*.css$
## Allow: /themes/*.css?
## Allow: /themes/*.js$
## Allow: /themes/*.js?
## Allow: /themes/*.gif
## Allow: /themes/*.jpg
## Allow: /themes/*.jpeg
## Allow: /themes/*.png
## # Directories
## Disallow: /includes/
## Disallow: /misc/
## Disallow: /modules/
## Disallow: /profiles/
## Disallow: /scripts/
## Disallow: /themes/
## # Files
## Disallow: /CHANGELOG.txt
## Disallow: /cron.php
## Disallow: /INSTALL.mysql.txt
## Disallow: /INSTALL.pgsql.txt
## Disallow: /INSTALL.sqlite.txt
## Disallow: /install.php
## Disallow: /INSTALL.txt
## Disallow: /LICENSE.txt
## Disallow: /MAINTAINERS.txt
## Disallow: /update.php
## Disallow: /UPGRADE.txt
## Disallow: /xmlrpc.php
## # Paths (clean URLs)
## Disallow: /admin/
## Disallow: /comment/reply/
## Disallow: /filter/tips/
## Disallow: /node/add/
## Disallow: /search/
## Disallow: /user/register/
## Disallow: /user/password/
## Disallow: /user/login/
## Disallow: /user/logout/
## # Paths (no clean URLs)
## Disallow: /?q=admin/
## Disallow: /?q=comment/reply/
## Disallow: /?q=filter/tips/
## Disallow: /?q=node/add/
## Disallow: /?q=search/
## Disallow: /?q=user/password/
## Disallow: /?q=user/register/
## Disallow: /?q=user/login/
## Disallow: /?q=user/logout/
</code></pre>

<p><a href="https://stackoverflow.com/a/40186203/7248543">Lo que no aparece como <em>&ldquo;Disallow&rdquo;</em> es permitido por defecto</a>, y la url a la que quiero acceder usando un robot es <a href="https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion">https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion</a>. No dice en ning칰n lugar del documento <code>Disallow: /documentosyleyes/</code>, entonces est치 permitido!</p>

<p>Pero por las dudas, chequeo esa url en particular:</p>

<pre><code class="language-r">robotstxt::paths_allowed(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion&quot;)
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

<p>Tengo luz verde para scrapear la web 游뗿.</p>

<h1 id="url-de-las-p치ginas-que-quiero-scrapear">Url de las p치ginas que quiero <em>scrapear</em></h1>

<p>Mi intenci칩n es descargar las sesiones de Diputados y Senadores desde el 1췈/1/2017 hasta el 31/3/2018. Al incorporar estos filtros manualmente en la p치gina <a href="https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion">https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion</a>, la url se va modificando para incorporar esta informaci칩n. Eso hace las cosas algo menos complicadas para mi, porque una vez que me doy cuenta c칩mo se comporta la url con esos filtros, puedo generar la url nueva y directamente acceder a ella. As칤 construyo la nueva url que se compone de la url original, algo de texto adicional y los filtros de fechas, de la siguiente forma:</p>

<pre><code class="language-r">date_init &lt;- &quot;01-01-2017&quot;
date_end  &lt;- &quot;31-03-2018&quot;

url_diputados &lt;- paste0(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=D&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=&quot;,
                        date_init,
                        &quot;&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=&quot;,
                        date_end,
                        &quot;&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;)
url_diputados
</code></pre>

<pre><code>## [1] &quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=D&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=01-01-2017&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=31-03-2018&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;
</code></pre>

<pre><code class="language-r">url_senadores &lt;- paste0(&quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=S&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=&quot;,
                        date_init,
                        &quot;&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=&quot;,
                        date_end,
                        &quot;&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;)

url_senadores
</code></pre>

<pre><code>## [1] &quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=S&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=01-01-2017&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=31-03-2018&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;
</code></pre>

<h1 id="y-ahora-c칩mo-selecciono-el-contenido-de-la-p치gina">Y ahora? C칩mo selecciono el contenido de la p치gina?</h1>

<p>Las p치ginas web son archivos html que el navegador interpreta y los transforma en lo que nosotros vemos. No voy a entrar en muchos detalles de c칩mo interpretar un archivo html (porque reci칠n estoy aprendiendo!), pero ac치 describo la  forma m치s intuitiva que encontr칠 para seleccionar el contenido del html al que quiero acceder.</p>

<p>Como se muestra en la animaci칩n a continuaci칩n, usando el <a href="https://selectorgadget.com/">Selector Gadget</a> (que tiene una extensi칩n para Google Chrome muy conveniente) me paro con el mouse sobre uno de los links a los pdfs y hago click. Ah칤 queda pintada toda la columna, porque pinta todos los elementos que son de la misma <em>clase</em> (no nos preocupemos de qu칠 es una <em>clase</em> ahora). Lo importante es que necesito <em>el nombre de la clase</em> para lo que viene a continuaci칩n, entonces copio el texto que aparece en el recuadro (en este caso es <code>.views-field-DS-File-IMG</code>).</p>

<p><img src="/post/scrapeando-las-sesiones-parlamentarias-de-uruguay/2018-04-03-scrapeando-las-sesiones-parlamentarias-de-uruguay/selector_gadget.gif" alt="" /></p>

<h1 id="web-scraping">Web scraping!</h1>

<h2 id="extraigo-los-pdfs">Extraigo los pdfs</h2>

<p>Ahora es que empiezo a usar el paquete <a href="https://github.com/tidyverse/rvest">rvest</a>. Defino una funci칩n que descarga los pdfs y los guarda en un dataframe, haciendo algunas transformaciones. Para explicar lo que hace la funci칩n voy a ignorar que como las sesiones son muchas, las muestra en dos p치ginas separadas. Es verdad que podr칤a haber puesto un poco m치s de esfuerzo en hacer esta funci칩n generalizable a <em>n</em> p치ginas, pero como sab칤a que ten칤a s칩lo 2, lo dej칠 as칤 游땒</p>

<pre><code class="language-r">library(dplyr)
library(rvest)
library(purrr)
library(tibble)
library(pdftools)

extract_pdf &lt;- function(url, pag = 1) {
  
  if (pag == 2) {
    url &lt;- url %&gt;%
      read_html() %&gt;%
      html_nodes(&quot;.pager-item a&quot;) %&gt;%
      html_attr(&quot;href&quot;) %&gt;%
      map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
      unlist()
    }
  
  pdfs &lt;- url %&gt;%
    read_html() %&gt;%
    html_nodes(&quot;.views-field-DS-File-IMG a&quot;) %&gt;%   # seleccionar clase
    html_attr(&quot;href&quot;) %&gt;%
    map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
    map(~ paste0(pdf_text(.), collapse = ' ')) %&gt;%
    map(~ stri_trans_general(tolower(.), id = &quot;latin-ascii&quot;)) %&gt;%
    map(~ stri_replace_all(., replacement = &quot;&quot;, regex = &quot;\\\n&quot;)) %&gt;% 
    map_df(function(pdf) {tibble(pdf)})
  
  return(pdfs)
}
</code></pre>

<p>La primera parte de la funci칩n es la que voy a ignorar, donde lo que hago es modificar la url para indicar que quiero ir a la segunda p치gina (se puede aplicar la misma l칩gica que la que voy a usar a continuaci칩n para interpretar esta parte del c칩digo).</p>

<p>Lo interesante pasa cuando empiezo a procesar la url: <code>read_html()</code> &ldquo;lee&rdquo; el contenido de la p치gina, para que pueda buscar lo que me interesa. Mi objetivo es encontrar todos los archivos pdf (por eso me interesaba conocer <em>el nombre de la clase</em> de esos elementos, que descubr칤 antes). Con <code>html_nodes()</code> voy extrayendo los <em>nodos</em> (tampoco nos preocupemos ahora por saber qu칠 son exactamente), y en este caso el <em>nodo</em> que me interesa es <code>.views-field-DS-File-IMG a</code>:</p>

<ul>
<li><p>tiene un punto adelante para indicar que se trata de elementos de una clase, seguido del nombre de la clase <code>views-field-DS-File-IMG</code> (lo que copiamos con el <em>Selector Gadget</em>),</p></li>

<li><p><code>a</code> es la etiqueta que html usa para definir elementos que son un hiperv칤nculo.</p></li>
</ul>

<p>Ahora puedo seleccionar el atributo <code>href</code>, que es el link al pdf, con la funci칩n <code>html_attr()</code>. Ac치 hay que tener cuidado porque la ruta es relativa (es decir que falta poner &ldquo;<a href="https://parlamento.gub.uy&quot;">https://parlamento.gub.uy&quot;</a> antes para tener la ruta completa).</p>

<p>Al aplicar la funci칩n hasta ac치, lo que tengo es una lista con una url por cada pdf que aparece en la p치gina. Por eso luego uso la funci칩n <code>purrr::map()</code> para aplicar a cada elemento de la lista (cada link a los pdfs), una funci칩n. Las transformaciones que aplico a cada elemento de la lista son, en forma sucesiva, las siguientes:</p>

<ul>
<li><p><code>paste0(&quot;https://parlamento.gub.uy&quot;, .)</code> completo la ruta absoluta, pegando &ldquo;<a href="https://parlamento.gub.uy&quot;">https://parlamento.gub.uy&quot;</a> adelante del link relativo,</p></li>

<li><p><code>paste0(pdf_text(.), collapse = ' ')</code> usando el paquete <code>pdftools</code> extraigo la informaci칩n del pdf con la funci칩n <code>pdf_text()</code> y colapso todas las p치ginas en un mismo string,</p></li>

<li><p><code>stri_trans_general(tolower(.), id = &quot;latin-ascii&quot;)</code> saco los caracteres especiales y dejo todo en min칰scula,</p></li>

<li><p><code>stri_replace_all(., replacement = &quot;&quot;, regex = &quot;\\\n&quot;)</code> elimino los saltos de l칤nea,</p></li>

<li><p><code>tibble(pdf)</code> transformo la lista en un dataframe.</p></li>
</ul>

<p>Entonces ahora extraigo los pdfs de las dos p치ginas y los junto en un 칰nico dataframe (voy a mostrar el proceso para Diputados, pero es an치logo para Senadores).</p>

<pre><code class="language-r">pdf_diputados_pag1 &lt;- extract_pdf(url_diputados, pag = 1)
pdf_diputados_pag2 &lt;- extract_pdf(url_diputados, pag = 2)

pdf_diputados &lt;- bind_rows(pdf_diputados_pag1, pdf_diputados_pag2)

library(knitr)
library(kableExtra)

knitr::kable(head(pdf_diputados) %&gt;%
               select(pdf) %&gt;% 
               mutate(pdf = substr(pdf, start=1, stop=500)),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> numero 4151                                                          montevideo, miercoles 14 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                               5춹 sesion (extraordinaria)
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4148                                                              montevideo, martes 6 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                                2춹 sesion
                                  presiden los senores representantes
                                                jorge gandini
                                                  (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4147                                                              montevideo, jueves 1춿 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                               1춹 sesion
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4146                                                             montevideo, jueves 8 de febrero de 2018
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               3춹 sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (preside </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4145                                                  montevideo, miercoles 7 de febrero de 2018
                 republica oriental del uruguay
                    diario de sesiones
                camara de representantes
                       2춹 sesion (extraordinaria)
                             preside el senor representante
                                  prof. jose carlos mahia
                                          (presidente)
                             actuan en secret </td>
  </tr>
  <tr>
   <td style="text-align:left;"> numero 4144                                                         montevideo, miercoles 20 de diciembre de 2017
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               1춹 sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (presi </td>
  </tr>
</tbody>
</table>

<h3 id="advertencia">丘멆잺 Advertencia 丘멆잺</h3>

<p>La funci칩n <code>pdftools::read_pdf()</code> lee los renglones de izquierda a derecha. En los Diarios de Sesiones hay algunas p치ginas que se organizan con texto en dos columnas, entonces hay renglones que, le칤dos de esa forma, quedan incoherentes. Esto hay que tenerlo en cuenta para ver si el tipo de an치lisis que quiero hacer tiene sentido o no. Por ejemplo, si lo que quiero es analizar <a href="https://es.wikipedia.org/wiki/N-grama"><em>n-gramas</em></a> donde el orden de las palabras es importante, voy a tener problemas porque estar칤a considerando palabras de distintas columnas de texto, como si vinieran una a continuaci칩n de la otra. Para analizar sentimiento con <a href="https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras"><em>bolsa de palabras (bag of words)</em></a> no hay problema, porque el orden de las palabras no es relevante.</p>

<h2 id="extraigo-fecha-y-n칰mero-de-sesi칩n">Extraigo fecha y n칰mero de sesi칩n</h2>

<p>Hago una segunda funci칩n para extraer otros la fecha y el n칰mero de la sesi칩n, porque se puede dar el caso de tener m치s de una sesi칩n en la misma fecha.</p>

<pre><code class="language-r">extract_metadata &lt;- function(url, info, pag = 1){
  if (info == &quot;fecha&quot;) nodes = &quot;td.views-field-DS-Fecha&quot;
  if (info == &quot;sesion&quot;) nodes = &quot;td.views-field-Ssn-Nro&quot;
  if (pag == 2){
    url &lt;- url %&gt;%
      read_html() %&gt;%
      html_nodes(&quot;.pager-item a&quot;) %&gt;%
      html_attr(&quot;href&quot;) %&gt;%
      map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)) %&gt;%
      unlist() 
    }
  
  url %&gt;% 
    read_html() %&gt;% 
    html_nodes(nodes) %&gt;% 
    html_text() %&gt;% 
    map(~str_extract(., &quot;[0-9\\-]+&quot;)) %&gt;%  # esta expresi칩n regular matchea tanto la fecha como el n칰mero de sesi칩n
    unlist()
}
</code></pre>

<p>Extraigo la fecha y la sesi칩n.</p>

<pre><code class="language-r"># extraigo fechas
pdf_fechas_diputados_pag1 &lt;- extract_metadata(url_diputados, info = &quot;fecha&quot;, pag = 1)
pdf_fechas_diputados_pag2 &lt;- extract_metadata(url_diputados, info = &quot;fecha&quot;, pag = 2)

# junto todos las fechas y las convierto en un df
pdf_fechas_diputados &lt;- c(pdf_fechas_diputados_pag1, pdf_fechas_diputados_pag2) %&gt;% 
  tbl_df() %&gt;% 
  transmute(fecha = as.Date(value, &quot;%d-%m-%Y&quot;))

# extraigo sesiones
pdf_sesion_diputados_pag1 &lt;- extract_metadata(url_diputados, info = &quot;sesion&quot;, pag = 1)
pdf_sesion_diputados_pag2 &lt;- extract_metadata(url_diputados, info = &quot;sesion&quot;, pag = 2)

# junto todos las sesiones y las convierto en un df
pdf_sesion_diputados &lt;- c(pdf_sesion_diputados_pag1, pdf_sesion_diputados_pag2) %&gt;% 
  tbl_df() %&gt;% 
  rename(sesion = value)

knitr::kable(head(pdf_sesion_diputados) %&gt;% select(fecha),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-14 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-06 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-01 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-08 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-20 </td>
  </tr>
</tbody>
</table>

<pre><code class="language-r">knitr::kable(head(pdf_sesion_diputados) %&gt;% select(sesion),
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> sesion </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 5 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 3 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
  </tr>
</tbody>
</table>
Juntando todo, armo el dataframe de Diputados con la fecha, la sesi칩n y el texto del pdf.


```r
diputados <- bind_cols(pdf_fechas_diputados, pdf_sesion_diputados, pdf_diputados) %>% 
  unite("fecha_sesion", c(fecha, sesion), remove = FALSE) %>%
  distinct() # la primer sesi칩n de la segunda p치gina es igual a la 칰ltima sesi칩n de la primera p치gina
```

Con este dataframe es con el que voy a trabajar para los Diputados, que tiene 66 sesiones.


```r
knitr::kable(head(diputados) %>% 
               mutate(pdf = substr(pdf, start=1, stop=500)), 
             format = "html") 
```

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha_sesion </th>
   <th style="text-align:left;"> fecha </th>
   <th style="text-align:left;"> sesion </th>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-14_5 </td>
   <td style="text-align:left;"> 2018-03-14 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> numero 4151                                                          montevideo, miercoles 14 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                               5춹 sesion (extraordinaria)
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-06_2 </td>
   <td style="text-align:left;"> 2018-03-06 </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> numero 4148                                                              montevideo, martes 6 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                                2춹 sesion
                                  presiden los senores representantes
                                                jorge gandini
                                                  (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-03-01_1 </td>
   <td style="text-align:left;"> 2018-03-01 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> numero 4147                                                              montevideo, jueves 1춿 de marzo de 2018
                  republica oriental del uruguay
                        diario de sesiones
                camara de representantes
                                               1춹 sesion
                                      preside el senor representante
                                               jorge gandini
                                                 (presidente) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-08_3 </td>
   <td style="text-align:left;"> 2018-02-08 </td>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> numero 4146                                                             montevideo, jueves 8 de febrero de 2018
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               3춹 sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (preside </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07_2 </td>
   <td style="text-align:left;"> 2018-02-07 </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> numero 4145                                                  montevideo, miercoles 7 de febrero de 2018
                 republica oriental del uruguay
                    diario de sesiones
                camara de representantes
                       2춹 sesion (extraordinaria)
                             preside el senor representante
                                  prof. jose carlos mahia
                                          (presidente)
                             actuan en secret </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-20_1 </td>
   <td style="text-align:left;"> 2017-12-20 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> numero 4144                                                         montevideo, miercoles 20 de diciembre de 2017
                  republica oriental del uruguay
                         diario de sesiones
                camara de representantes
                               1춹 sesion (extraordinaria)
                                  presiden los senores representantes
                                           prof. jose carlos mahia
                                                   (presi </td>
  </tr>
</tbody>
</table>

<p>Y con este dataframe es con el que voy a trabajar para los Senadores, que tiene 59 sesiones.</p>

<pre><code class="language-r">knitr::kable(head(senadores) %&gt;% 
               mutate(pdf = substr(pdf, start=1, stop=500)), 
             format = &quot;html&quot;) 
</code></pre>

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> fecha_sesion </th>
   <th style="text-align:left;"> fecha </th>
   <th style="text-align:left;"> sesion </th>
   <th style="text-align:left;"> pdf </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 2018-03-06_1 </td>
   <td style="text-align:left;"> 2018-03-06 </td>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> n.췈 1 - tomo 578                                                                                                      6 de marzo de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                  camara de senadores                                      cuarto periodo de la xlviii legislatura </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-27_57 </td>
   <td style="text-align:left;"> 2018-02-27 </td>
   <td style="text-align:left;"> 57 </td>
   <td style="text-align:left;"> n.췈 57 - tomo 577                                                                                                    27 de febrero de 2018                                            republica oriental del uruguay                            diario de sesiones                                                                       de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                   57 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-21_56 </td>
   <td style="text-align:left;"> 2018-02-21 </td>
   <td style="text-align:left;"> 56 </td>
   <td style="text-align:left;"> n.췈 56 - tomo 577                                                                                                   21 de febrero de 2018                                            republica oriental del uruguay                            diario de sesiones                                                                       de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  56.춹 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-07_55 </td>
   <td style="text-align:left;"> 2018-02-07 </td>
   <td style="text-align:left;"> 55 </td>
   <td style="text-align:left;"> n.췈 55 - tomo 577                                                                                                       7 de febrero de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  55. </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2018-02-06_54 </td>
   <td style="text-align:left;"> 2018-02-06 </td>
   <td style="text-align:left;"> 54 </td>
   <td style="text-align:left;"> n.췈 54 - tomo 577                                                                                                    6 de febrero de 2018                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  54.춹 s </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2017-12-27_53 </td>
   <td style="text-align:left;"> 2017-12-27 </td>
   <td style="text-align:left;"> 53 </td>
   <td style="text-align:left;"> n.췈 53 - tomo 577                                                                                                27 de diciembre de 2017                                            republica oriental del uruguay                           diario de sesiones                                                                      de la                camara de senadores                                       tercer periodo de la xlviii legislatura                                                  53.춹 se </td>
  </tr>
</tbody>
</table>

<h1 id="tad치">Tad치 游꿀</h1>

<p>Ahora con los datos en este formato, estoy en condiciones de analizar las sesiones!</p>

<p>Para m치s informaci칩n acerca de c칩mo trabajar con datos de la web, hay un <a href="https://www.datacamp.com/community/tutorials/r-web-scraping-rvest">tutorial de Arvid Kingl en Datacamp en ingl칠s para usar <code>rvest</code></a> y hay un <a href="https://www.datacamp.com/courses/working-with-web-data-in-r">curso de Charlotte Wickham y Oliver Keyes, tambi칠n en ingl칠s y en Datacamp,</a> que habla adem치s de otras formas de consumir datos de la web, como a trav칠s de APIs.</p>

<p>Si quer칠s analizar las sesiones fuera de R, o prefer칤s ahorrarte el paso de hacer scraping, <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary/blob/master/data/diputados.csv">ac치 ten칠s las sesiones de Diputados en formato csv</a>, y <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary/blob/master/data/senadores.csv">ac치 las sesiones de Senadores en formato csv</a> para hacer tus an치lisis! (Gracias <a href="https://twitter.com/rolaguna">Rodrigo</a> por la sugerencia!)</p>

<p>Todo lo que us칠 en este art칤culo (y m치s!) est치 <a href="https://github.com/d4tagirl/uruguayan_parliamentary_session_diary">disponible en GitHub</a>. Espero que haya resultado 칰til! Dejame tus comentarios abajo o <a href="https://twitter.com/intent/tweet?user_id=114258616">mencioname en Twitter</a> 游땎</p>

                </section>
            </article>

            

            
                <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'd4tagirl'; 

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/d4tagirl">
        <i class="fa fa-github-square"></i>
    </a>
    
    <a class="symbol" href="https://www.linkedin.com/in/d4tagirl">
        <i class="fa fa-linkedin-square"></i>
    </a>
    
    <a class="symbol" href="https://www.twitter.com/d4tagirl">
        <i class="fa fa-twitter-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       춸 Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> Daniela V치zquez
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', '90827501', 'auto');
	
	ga('send', 'pageview');
}
</script>





    </body>
</html>
