---
layout: post
title:  Code to compare Facebook and Youtube's comments
date: "2017-05-30 02:11:29 UYT"
published: true
tags: [skip_index]
---

<!--more-->
<br />
```{r echo = FALSE, message = FALSE, warning = FALSE} 
# you can find everything I use here:
# https://github.com/d4tagirl/John-Oliver-sentiment-analysis

library(dplyr)
library(knitr)
knitr::opts_chunk$set(fig.align = 'center', screenshot.force = FALSE, fig.cap = "",
                      dpi = 120)
options(width = 80, dplyr.width = 150)
```

# Working with Facebook comments

## Cleaning and tidying the data

Here I replicate the work done on Youtube comments.

```{r eval = FALSE, message = FALSE, warning = FALSE}
fb_comments <- fb_comments %>% 
  filter(com_text != "") %>%
  left_join(videos_fb, by = c("post_id_fb" = "id")) %>% 
  group_by(short_title) %>% 
  mutate(n = n(),
         com_created = as.Date(com_created)) %>% 
  ungroup() %>% 
  filter(n >= 100) %>% 
  select(short_title, video_id = ids, post_id_fb, com_text, com_id, com_created)

tidy_fb_comments <- fb_comments %>%
  tidytext::unnest_tokens(word, com_text) %>%
  anti_join(stop_words, by = "word") 
```

```{r echo = FALSE, warning = FALSE, message = FALSE}
library(dplyr)
library(knitr)
library(purrr)
library(tibble)
library(stringr)
library(readr)
library(tidytext)
library(ggplot2)
library(tidyr)

url_csv <- 'https://github.com/d4tagirl/John-Oliver-sentiment-analysis/raw/master/blog_post_csv/fb_comments.csv'
fb_comments <- read_csv(url(url_csv)) %>%
  select(-1)

tidy_fb_comments <- fb_comments %>%
  tidytext::unnest_tokens(word, com_text) %>%
  anti_join(stop_words, by = "word") 
```

# Plot the most positive and most negative words

Once I have a tidy dataframe, I plot the most positive and most negative words on Facebook to compare them in the original article with the Youtube ones.

```{r warning = FALSE, message = FALSE, fig.height = 4}
fb_pos_neg_words <- tidy_fb_comments %>%  
  inner_join(get_sentiments("bing"), by = "word") %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_fill_manual(values = c("red2", "green3")) +
  facet_wrap(~sentiment, scales = "free_y") +
  ylim(0, 2500) +
  xlab(NULL) +
  ylab(NULL) +
  coord_flip() +
  theme_minimal()
```

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.height = 3}
fb_pos_neg_words
```

# Sentiment by comment and by video

As I did for the Youtube videos, I calculate the sentiment for every comment and then for every video.

```{r warning = FALSE, message = FALSE}
fb_comment_sent <- tidy_fb_comments  %>%
  inner_join(get_sentiments("bing"), by = "word") %>% 
  count(com_id, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>% 
  ungroup() %>% 
  left_join(fb_comments, by = "com_id")

fb_title_sent <- fb_comment_sent %>% 
  group_by(short_title) %>% 
  summarise(pos        = sum(positive),
            neg        = sum(negative),
            sent_mean  = mean(sentiment),
            sentiment  = pos - neg) %>% 
  ungroup() %>% 
  arrange(-sentiment)
```

# Joining Facebook and Youtube comments

I join the Youtube and Facebook's sentiment by video tables to compare comments. I have to filter the videos present in both platforms to make a fair comparison.

```{r echo = FALSE, warning = FALSE, message = FALSE}
url_csv <- 'https://github.com/d4tagirl/John-Oliver-sentiment-analysis/raw/master/blog_post_csv/yt_title_sent.csv'
yt_title_sent <- read_csv(url(url_csv)) %>%
  select(-1)
```

```{r warning = FALSE, message = FALSE, fig.height = 4}
comments_by_title <- yt_title_sent %>% 
  inner_join(fb_title_sent, by = c("short_title" = "short_title")) %>% 
  select(vid_created, 
         short_title, 
         mean_sent_yt = sent_mean.x,
         mean_sent_fb = sent_mean.y) %>% 
  ungroup() %>% 
  mutate(diff = mean_sent_fb - mean_sent_yt,
         short_title = reorder(short_title, -diff)) %>% 
  arrange(desc(diff))
```

And now I can plot the sentiment for every video on each platforms, ordered by published date.  
  
```{r warning = FALSE, message = FALSE, fig.height = 4}  
library(plotly)
ggplotly(comments_by_title %>%
  
  ggplot(aes(x = reorder(short_title, vid_created), 
             text = paste(short_title, "<br />",  vid_created))) +
  geom_line(aes(y = mean_sent_fb, group = 1), color = "blue") +
  geom_line(aes(y = mean_sent_yt, group = 1), color = "red") +
  geom_hline(yintercept = 0) +
  xlab(NULL) +
  ylab(NULL) +
  theme_minimal() +
  theme(axis.text.x = element_blank()),
tooltip = "text")
```

